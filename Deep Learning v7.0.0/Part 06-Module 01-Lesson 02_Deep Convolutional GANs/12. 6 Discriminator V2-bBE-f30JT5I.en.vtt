WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.889
In defining a complete GAN,

00:00:01.889 --> 00:00:04.455
your first task will be to build the discriminator.

00:00:04.455 --> 00:00:07.769
This is a convolutional classifier like you've built before,

00:00:07.769 --> 00:00:09.959
only without any max-pooling layers.

00:00:09.960 --> 00:00:13.140
Instead, we'll be using strided convolutional layers.

00:00:13.140 --> 00:00:15.419
The inputs to the discriminator are going to be

00:00:15.419 --> 00:00:20.655
SVA Gen training images or generated images that are 32 by 32 by three.

00:00:20.655 --> 00:00:22.170
Accepting this as input,

00:00:22.170 --> 00:00:25.215
you'll then want to define a few convolutional hidden layers.

00:00:25.214 --> 00:00:27.800
You will flatten the output of your last convolutional layer

00:00:27.800 --> 00:00:30.484
and pass it to a fully-connected layer at the end.

00:00:30.484 --> 00:00:33.439
As before, we want this to produce a sigmoid output,

00:00:33.439 --> 00:00:36.159
that indicates whether an image is fake or real.

00:00:36.159 --> 00:00:39.949
Also, as before, we'll apply the sigmoid function in the lost function,

00:00:39.950 --> 00:00:42.095
BCE with largest loss later.

00:00:42.094 --> 00:00:44.420
Now, for the depths of the convolutional layers,

00:00:44.420 --> 00:00:48.170
I suggest starting with a smaller depth than is indicated here.

00:00:48.170 --> 00:00:50.329
I suggest starting with 32 filters in

00:00:50.329 --> 00:00:53.170
the first layer and then double that depth as you add layers.

00:00:53.170 --> 00:00:57.005
So, from 32 to 64 to 128 and so on.

00:00:57.005 --> 00:00:59.885
You'll also want to use batch normalization on each layer

00:00:59.884 --> 00:01:03.695
except the first convolutional layer and final linear output layer.

00:01:03.695 --> 00:01:07.640
You can read about BatchNorm2D at this link to the documentation here.

00:01:07.640 --> 00:01:11.030
In general, each layer should look something like strided convolution,

00:01:11.030 --> 00:01:14.510
followed by batch norm and then a Leaky ReLu activation function.

00:01:14.510 --> 00:01:15.844
So, in the cell below,

00:01:15.844 --> 00:01:19.219
I've actually provided a helper function to put these layers together,

00:01:19.219 --> 00:01:22.459
this function which I named conv for convolutional layers,

00:01:22.459 --> 00:01:24.064
takes in the same parameters as

00:01:24.064 --> 00:01:27.590
a typical convolutional layer with one additional parameter,

00:01:27.590 --> 00:01:30.730
batch_norm which is a Boolean variable true or false.

00:01:30.730 --> 00:01:32.865
Then, based on these past time parameters,

00:01:32.864 --> 00:01:35.849
it creates a sequential series of one or two layers,

00:01:35.849 --> 00:01:39.964
a strided convolutional layer and an optional batch norm layer.

00:01:39.965 --> 00:01:42.814
We'll create these using PyTorches sequential container,

00:01:42.814 --> 00:01:45.769
which takes in a list of layers and creates layers according

00:01:45.769 --> 00:01:48.700
to the order that they're passed in to the sequential container.

00:01:48.700 --> 00:01:51.019
You can read more about that in the documentation here.

00:01:51.019 --> 00:01:53.104
So, let's look at this line by line.

00:01:53.105 --> 00:01:57.685
First, I'm preparing to create a list of layers and creating an empty list named layers.

00:01:57.685 --> 00:02:00.545
Then, I'm defining a strided convolutional layer.

00:02:00.545 --> 00:02:02.704
I'm passing in all the relevant parameters,

00:02:02.704 --> 00:02:04.144
input and output channels,

00:02:04.144 --> 00:02:07.744
kernel size stride and padding and bias is set to false,

00:02:07.745 --> 00:02:10.175
so that these layers are not offset by any amount.

00:02:10.175 --> 00:02:13.040
This is pretty typical for a strided convolutional layer,

00:02:13.039 --> 00:02:16.069
I should know that I'm expecting that you'll use a kernel size of

00:02:16.069 --> 00:02:19.489
four and a stride of two for this strided convolutions.

00:02:19.490 --> 00:02:23.235
I've set the default parameters accordingly, a kernel size of four,

00:02:23.235 --> 00:02:26.165
stride of two and padding of one will ensure that

00:02:26.164 --> 00:02:28.759
each strided convolutional layer down-samples it's

00:02:28.759 --> 00:02:32.049
input by a factor of two in the X and Y dimensions.

00:02:32.050 --> 00:02:34.820
So, with the kernel size of four and stride two if

00:02:34.819 --> 00:02:37.590
this layer sees a 32 by 32 images input,

00:02:37.590 --> 00:02:40.430
it will output a 16 by 16 image.

00:02:40.430 --> 00:02:44.379
Then you can see that I'm appending that convolutional layer to my list of layers.

00:02:44.379 --> 00:02:47.240
Next, if the batch norm parameter is set to true,

00:02:47.240 --> 00:02:49.715
which is the default here in the function definition,

00:02:49.715 --> 00:02:53.569
I will add a batch norm layer on the output of our convolutional layer.

00:02:53.569 --> 00:02:55.819
I can do this with a call to BatchNorm2D and

00:02:55.819 --> 00:02:58.400
pass in the number of outputs it should operate on,

00:02:58.400 --> 00:03:00.230
a number of output channels.

00:03:00.229 --> 00:03:03.024
In the same line, I'm adding this to our list of layers.

00:03:03.025 --> 00:03:04.819
Now, if batch normis set to false,

00:03:04.819 --> 00:03:08.465
I will not enter this if statement and I won't add a BatchNorm2D layer.

00:03:08.465 --> 00:03:11.210
Finally, I'm using PyTorches sequential wrapper which

00:03:11.210 --> 00:03:13.835
takes in our list of layers and this will return those layers,

00:03:13.835 --> 00:03:17.750
whether it's one convolutional layer or a convolutional layer and a batch norm layer.

00:03:17.750 --> 00:03:19.939
Now, it will be up to you to use

00:03:19.939 --> 00:03:23.870
this conv helper function to construct a complete discriminator class.

00:03:23.870 --> 00:03:26.194
Here's the starting code for the discriminator.

00:03:26.194 --> 00:03:30.530
You're expected to create at least three convolutional layers to complete this network,

00:03:30.530 --> 00:03:32.830
you should increase the depth of these layers as you go.

00:03:32.830 --> 00:03:36.860
The initial depth should be defined by this input parameter conv_dim.

00:03:36.860 --> 00:03:39.860
This is set by default to my recommendation which has

00:03:39.860 --> 00:03:42.740
a depth of 32 for your first convolutional layer.

00:03:42.740 --> 00:03:45.500
Now, make sure to apply the correct batch norm functions using

00:03:45.500 --> 00:03:50.449
our helper function and apply Leaky ReLu activations in the forward function here,

00:03:50.449 --> 00:03:53.899
it may be helpful to look at this diagram here as inspiration.

00:03:53.899 --> 00:03:56.449
At the end of a few strided convolutional layers,

00:03:56.449 --> 00:03:59.060
you'll also have to include a fully connected layer that will

00:03:59.060 --> 00:04:01.969
be responsible for returning some discriminator logits.

00:04:01.969 --> 00:04:04.250
Alright. Next. I'll go over a solution to

00:04:04.250 --> 00:04:06.259
this discriminator class and then we'll go

00:04:06.259 --> 00:04:08.729
over the second part of the GAN, the generator.

