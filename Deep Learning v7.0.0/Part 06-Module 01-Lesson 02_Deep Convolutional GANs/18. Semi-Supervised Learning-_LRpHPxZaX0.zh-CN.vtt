WEBVTT
Kind: captions
Language: zh-CN

00:00:00.389 --> 00:00:01.929
目前为止 我们已经大体了解了

00:00:01.929 --> 00:00:04.580
如何使用生成对抗网络 (GAN) 生成图像

00:00:04.580 --> 00:00:06.939
虽然生成图像很有趣 并且它

00:00:06.939 --> 00:00:09.099
与多个重要的人工智能 (AI) 研究方向

00:00:09.099 --> 00:00:12.309
相关 但它只能用于几个利基

00:00:12.310 --> 00:00:15.339
领域 例如开发图像编辑软件

00:00:15.339 --> 00:00:17.589
以最终实际生成

00:00:17.589 --> 00:00:18.839
不错的图像

00:00:18.839 --> 00:00:22.210
生成对抗网络 (GAN) 的一个更为普遍有用的应用

00:00:22.210 --> 00:00:25.179
是半监督学习 我们使用生成对抗网络 (GAN)

00:00:25.179 --> 00:00:28.929
来提高分类器的性能

00:00:28.929 --> 00:00:32.530
很多较新的产品和服务使用分类

00:00:32.530 --> 00:00:33.759
而非生成

00:00:33.759 --> 00:00:35.229
所以我想你们大多数人

00:00:35.229 --> 00:00:36.820
更想知道如何

00:00:36.820 --> 00:00:39.399
构建好的分类器 而非如何

00:00:39.399 --> 00:00:41.199
生成图像

00:00:41.200 --> 00:00:43.750
基于深度学习的

00:00:43.750 --> 00:00:46.210
对象识别模型经过训练后往往

00:00:46.210 --> 00:00:48.219
能达到超人般的准确度

00:00:48.219 --> 00:00:51.189
但现代的深度学习算法在学习过程中

00:00:51.189 --> 00:00:54.219
的效率还不及人类

00:00:54.219 --> 00:00:55.839
想想用于训练地址编号转录模型的

00:00:55.840 --> 00:00:59.859
“街景门牌号”数据库

00:00:59.859 --> 00:01:02.049
此数据库包含成千上万

00:01:02.049 --> 00:01:04.759
地址编号的带标签照片

00:01:04.760 --> 00:01:06.550
回忆一下当你刚开始识字时

00:01:06.549 --> 00:01:08.799
老师并不会带你在整个城市

00:01:08.799 --> 00:01:11.349
转一圈 去认识所有地址编号

00:01:11.349 --> 00:01:13.359
告诉你每个上面的数字是什么

00:01:13.359 --> 00:01:15.010
从这一点来看 深度学习

00:01:15.010 --> 00:01:18.400
似乎比人需要更多的训练数据

00:01:18.400 --> 00:01:20.080
但从另一点来说 我们也可以

00:01:20.079 --> 00:01:23.289
认为深度学习并没有获得同等的学习机会

00:01:23.290 --> 00:01:25.660
因为深度学习模型的整个生命经验

00:01:25.659 --> 00:01:29.409
只有一堆带标签的图像

00:01:29.409 --> 00:01:32.259
人能够从老师提供的很少的

00:01:32.260 --> 00:01:33.250
例子中学习

00:01:33.250 --> 00:01:35.469
但这可能是因为人还

00:01:35.469 --> 00:01:38.049
具有各种各样的感官体验

00:01:38.049 --> 00:01:40.149
去体验那些不带标签的事物

00:01:40.150 --> 00:01:42.190
当我们行走于周围环境时 我们能看到

00:01:42.189 --> 00:01:43.959
不同照明条件 以及不同角度下

00:01:43.959 --> 00:01:46.759
的物体等等

00:01:46.760 --> 00:01:49.780
我们的大多数体验是没有标签的

00:01:49.780 --> 00:01:53.079
我们的很多体验在

00:01:53.079 --> 00:01:55.000
现代深度学习的训练集中

00:01:55.000 --> 00:01:57.040
是不存在的

00:01:57.040 --> 00:01:58.750
提高深度学习模型

00:01:58.750 --> 00:02:01.150
学习效率的一条途径

00:02:01.150 --> 00:02:03.609
是半监督学习

00:02:03.609 --> 00:02:05.890
在半监督学习中 模型可以

00:02:05.890 --> 00:02:08.710
正常学习带标签的示例

00:02:08.710 --> 00:02:11.000
但它也可以通过学习不带标签的示例

00:02:11.000 --> 00:02:14.349
来提高分类能力 尽管这些示例

00:02:14.349 --> 00:02:16.629
不具有类标签

00:02:16.629 --> 00:02:19.090
通常情况下 获取不带标签的数据

00:02:19.090 --> 00:02:22.819
要比获取带标签的数据更容易 成本也更低

00:02:22.819 --> 00:02:24.819
例如 互联网基本上

00:02:24.819 --> 00:02:26.979
是一个免费数据源 提供无限量的

00:02:26.979 --> 00:02:30.759
无标签文本、图像和视频

00:02:30.759 --> 00:02:33.929
要使用生成对抗网络 (GAN) 进行半监督分类

00:02:33.930 --> 00:02:36.830
我们需要将 GAN 作为分类器

00:02:36.830 --> 00:02:39.040
GAN 包含两个模型 生成器

00:02:39.039 --> 00:02:40.810
和辨别器

00:02:40.810 --> 00:02:43.900
通常我们两个一起训练 在训练结束时

00:02:43.900 --> 00:02:45.219
丢掉辨别器

00:02:45.219 --> 00:02:47.740
我们通常只关心使用生成器

00:02:47.740 --> 00:02:49.810
创建样本

00:02:49.810 --> 00:02:52.689
而辨别器是次要的

00:02:52.689 --> 00:02:55.030
并且仅用于训练生成器

00:02:55.030 --> 00:02:57.520
而对于半监督学习 我们实际上

00:02:57.520 --> 00:03:00.880
主要关注辨别器 而非生成器

00:03:00.879 --> 00:03:03.849
我们要将辨别器扩展为分类器

00:03:03.849 --> 00:03:07.539
然后在训练结束时使用它来对新数据分类

00:03:07.539 --> 00:03:10.509
我们实际上可以扔掉生成器 除非我们也想

00:03:10.509 --> 00:03:12.429
生成图像

00:03:12.430 --> 00:03:14.530
对于半监督分类

00:03:14.530 --> 00:03:17.469
生成器是次要的 仅用于

00:03:17.469 --> 00:03:19.629
训练辨别器

00:03:19.629 --> 00:03:22.060
目前为止 我们用了仅有一个 sigmoid 输出

00:03:22.060 --> 00:03:24.420
的辨别器网络

00:03:24.419 --> 00:03:26.949
这个 sigmoid 输出会给我们

00:03:26.949 --> 00:03:30.009
输出为真实而非虚假的概率

00:03:30.009 --> 00:03:32.889
我们将它变成具有两个输出的 softmax

00:03:32.889 --> 00:03:34.989
一个对应于 real 类

00:03:34.990 --> 00:03:37.390
另一个对应于 fake 类

00:03:37.389 --> 00:03:40.899
如果我们将 fake 类的 logit 硬编码为 0

00:03:40.900 --> 00:03:44.020
那么 softmax 就会跟之前的 sigmoid 一样

00:03:44.020 --> 00:03:45.689
计算完全相同的概率

00:03:45.689 --> 00:03:49.000
要将辨别器变成一个有用的分类器

00:03:49.000 --> 00:03:52.060
我们可以将 real 类拆分为我们想要识别的

00:03:52.060 --> 00:03:53.800
所有不同的类

00:03:53.800 --> 00:03:56.980
例如 要分类 10 个不同的 SVHN 数字

00:03:56.979 --> 00:03:59.379
0 到 9 我们可以使辨别器

00:03:59.379 --> 00:04:02.560
共有 11 个不同的类 real 0

00:04:02.560 --> 00:04:05.530
real 1 一直到 real 9

00:04:05.530 --> 00:04:09.400
以及一个额外的类 即所有假图像的 fake 类

00:04:09.400 --> 00:04:12.460
现在 我们可以使用两个代价函数的和来训练模型

00:04:12.460 --> 00:04:14.230
对于带标签的示例

00:04:14.229 --> 00:04:17.500
我们可以使用常规的监督学习交叉熵代价函数

00:04:17.500 --> 00:04:19.689
对于所有其他示例以及

00:04:19.689 --> 00:04:21.790
来自生成器的假样本

00:04:21.790 --> 00:04:23.950
我们可以添加生成对抗网络 (GAN) 成本

00:04:23.949 --> 00:04:26.043
要获得输入为真的概率

00:04:26.043 --> 00:04:27.459
我们只需要对所有 real 类

00:04:27.459 --> 00:04:29.289
的概率求和

00:04:29.290 --> 00:04:32.890
一般的分类器只能学习带标签图像

00:04:32.889 --> 00:04:35.409
而这个新的分类器可以学习带标签图像

00:04:35.410 --> 00:04:39.580
不带标签的真实图像 以及甚至是来自生成器的假图像

00:04:39.579 --> 00:04:42.109
将这些结合起来 最终测试集会获得

00:04:42.110 --> 00:04:44.379
非常低的误差 因为我们有很多不同的

00:04:44.379 --> 00:04:48.100
信息源 即使并未使用太多带标签示例

00:04:48.100 --> 00:04:49.689
要让它的性能达到最好 我们

00:04:49.689 --> 00:04:52.420
还要使用一个技巧 叫作 “特征匹配”

00:04:52.420 --> 00:04:54.939
特征匹配的想法是向生成器的

00:04:54.939 --> 00:04:57.069
代价函数添加一个项

00:04:57.069 --> 00:05:00.040
惩罚训练数据上某些特征集

00:05:00.040 --> 00:05:02.105
的平均值和生成样本的

00:05:02.105 --> 00:05:03.980
特征集的平均值之间的

00:05:03.980 --> 00:05:05.774
绝对平均误差

00:05:05.774 --> 00:05:07.939
特征集可以是来自辨别器的

00:05:07.939 --> 00:05:09.469
任何隐藏单元组

00:05:09.470 --> 00:05:12.660
在一篇名为 “改进训练生成对抗网络 (GAN) 的技术” 的论文中

00:05:12.660 --> 00:05:16.240
Open AI 使用 SVHN 中仅 1,000 个带标签的示例进行训练

00:05:16.240 --> 00:05:20.509
能实现低于 6% 的误差率

00:05:20.509 --> 00:05:23.180
相比之下 之前最好的半监督

00:05:23.180 --> 00:05:28.840
学习算法的误差率为 16% 几乎是三倍

00:05:28.839 --> 00:05:31.119
当然 全监督算法

00:05:31.120 --> 00:05:33.730
使用成千上万的带标签示例进行训练

00:05:33.730 --> 00:05:36.290
能够实现低于 2% 的误差率

00:05:36.290 --> 00:05:37.689
所以相比收集巨量带标签数据

00:05:37.689 --> 00:05:40.240
进行训练的蛮力方法 

00:05:40.240 --> 00:05:43.720
半监督学习仍然还有很大差距

00:05:43.720 --> 00:05:45.760
一般来说 带标签数据是一个瓶颈

00:05:45.759 --> 00:05:48.730
它决定了我们用机器学习能或不能

00:05:48.730 --> 00:05:50.140
解决哪些任务

00:05:50.139 --> 00:05:52.769
希望使用半监督生成对抗网络 (GAN)

00:05:52.769 --> 00:05:54.519
你可以解决之前无法解决的

00:05:54.519 --> 00:05:56.939
很多问题

