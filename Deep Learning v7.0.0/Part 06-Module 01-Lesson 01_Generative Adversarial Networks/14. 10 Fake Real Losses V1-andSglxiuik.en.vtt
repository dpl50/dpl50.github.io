WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.660
Now that we've defined a discriminator D and generator G,

00:00:03.660 --> 00:00:06.435
we need to define an optimization strategy.

00:00:06.434 --> 00:00:09.224
This involves defining two different optimizers,

00:00:09.224 --> 00:00:12.404
one for our discriminator and one for our generator networks.

00:00:12.404 --> 00:00:16.214
We'll also have to define different loss functions for each of these models.

00:00:16.214 --> 00:00:17.670
This will allow us to perform

00:00:17.670 --> 00:00:21.030
the necessary back propagation and optimization steps during training.

00:00:21.030 --> 00:00:24.105
Now, let's talk about how the discriminator trains first.

00:00:24.105 --> 00:00:25.754
We know that during training,

00:00:25.754 --> 00:00:27.855
the discriminator will have two losses,

00:00:27.855 --> 00:00:31.274
one for real training images and one for fake images.

00:00:31.274 --> 00:00:34.259
Its aim is to label all real training images

00:00:34.259 --> 00:00:37.799
close to one and all fake images as close to zero,

00:00:37.799 --> 00:00:40.759
and so we'll compare the output of our discriminator in

00:00:40.759 --> 00:00:44.629
these cases to the real label one or the fake label zero.

00:00:44.630 --> 00:00:48.600
I'll also go over a couple of strategies for creating a numerically stable loss.

00:00:48.600 --> 00:00:54.750
Things like smoothing the label from a value from one to 0.9 and using BCEWithLogitsLoss.

00:00:54.750 --> 00:00:56.354
Now, in the generator case,

00:00:56.354 --> 00:01:00.024
we'll have actually an opposing loss that aims to trick the discriminator.

00:01:00.024 --> 00:01:01.409
So, to train the generator,

00:01:01.409 --> 00:01:03.559
we'll actually look at the output of the discriminator

00:01:03.560 --> 00:01:07.075
again as it's applied to these generated fake images.

00:01:07.075 --> 00:01:09.769
Only this time or one its output to be real,

00:01:09.769 --> 00:01:11.859
one, when it sees these images.

00:01:11.859 --> 00:01:14.840
So, as we train the discriminator and the generator,

00:01:14.840 --> 00:01:18.365
we basically need a way of calculating two different types of losses.

00:01:18.364 --> 00:01:21.484
One that checks if the output of the discriminator is close to one

00:01:21.484 --> 00:01:24.715
or real and one that checks if it's close to zero or fake.

00:01:24.715 --> 00:01:26.070
So, in the below cell,

00:01:26.069 --> 00:01:28.229
your task will be to define two functions,

00:01:28.230 --> 00:01:30.060
real loss and fake loss.

00:01:30.060 --> 00:01:32.765
They should just take in the output from the discriminator.

00:01:32.765 --> 00:01:35.920
So, the output logits for a batch of input image data.

00:01:35.920 --> 00:01:37.575
In the real last case,

00:01:37.575 --> 00:01:39.719
there's an additional parameter, smooth.

00:01:39.719 --> 00:01:42.905
This will be either true or false and defaults to false.

00:01:42.905 --> 00:01:44.299
But basically, if it's true,

00:01:44.299 --> 00:01:49.495
we'll smooth our ground truth labels so that instead of being all ones, they're all 0.9.

00:01:49.495 --> 00:01:50.984
As Ian mentioned earlier,

00:01:50.984 --> 00:01:54.859
this is to make the discriminator numerically stable and to help it generalize better.

00:01:54.859 --> 00:01:56.629
Okay. So, for this real loss function,

00:01:56.629 --> 00:01:59.060
you should compare these discriminator outputs to

00:01:59.060 --> 00:02:03.519
the ground truth labels which will be one or 0.9 depending on your smooth parameter,

00:02:03.519 --> 00:02:05.274
and you should return that loss,

00:02:05.275 --> 00:02:07.715
and you'll do the same kind of thing for a fake loss,

00:02:07.715 --> 00:02:10.474
only comparing the outputs to the value zero,

00:02:10.474 --> 00:02:12.025
the value for a fake labels.

00:02:12.025 --> 00:02:14.414
When I say compare, I want you to use

00:02:14.414 --> 00:02:18.905
BCEWithLogitsLoss to compare the discriminator outputs to the true labels.

00:02:18.905 --> 00:02:21.175
Let's click on this loss functions documentation.

00:02:21.175 --> 00:02:23.719
Okay. So, here's our loss function and we can see that it

00:02:23.719 --> 00:02:27.094
combines a Sigmoid layer with a BCELoss.

00:02:27.094 --> 00:02:30.484
BCE loss is binary cross entropy loss

00:02:30.485 --> 00:02:33.965
which is well suited for tasks in which we're looking at just two classes.

00:02:33.965 --> 00:02:36.069
In this case, real and fake images.

00:02:36.069 --> 00:02:38.329
This is just our normal cross entropy loss,

00:02:38.330 --> 00:02:40.520
but applied to cases with two classes,

00:02:40.520 --> 00:02:43.010
and we can read here that this version is more numerically

00:02:43.009 --> 00:02:46.179
stable than using a sigmoid plus BCELoss.

00:02:46.180 --> 00:02:50.269
Because this applies a sigmoid activation function to the input that sees,

00:02:50.269 --> 00:02:54.034
this is why I did not include a sigmoid activation in our model definition,

00:02:54.034 --> 00:02:55.745
and as with any loss function,

00:02:55.745 --> 00:02:59.185
we can see that this takes in some inputs x and some targets y.

00:02:59.185 --> 00:03:01.064
In this case, that will be the logits,

00:03:01.064 --> 00:03:02.603
the output of our discriminator,

00:03:02.604 --> 00:03:04.810
and some target labels to compare them too.

00:03:04.810 --> 00:03:06.175
So, back to our notebook,

00:03:06.175 --> 00:03:09.680
I want you to define true labels for the real and fake cases,

00:03:09.680 --> 00:03:14.694
and use BCEWithLogitsLoss to compare our discriminator outputs to these two labels.

00:03:14.694 --> 00:03:16.699
You can create labels by using something like

00:03:16.699 --> 00:03:20.329
torch.ones or a torch.zeros and passing in a batch size.

00:03:20.330 --> 00:03:22.820
Then, each of these functions should return

00:03:22.819 --> 00:03:26.209
the value of the calculated BCE with budgets loss.

00:03:26.210 --> 00:03:28.020
After defining these loss functions,

00:03:28.020 --> 00:03:30.200
to complete our optimization strategy,

00:03:30.199 --> 00:03:33.123
I want you to define two different atom optimizers,

00:03:33.123 --> 00:03:35.634
one for our discriminator and our generator.

00:03:35.634 --> 00:03:38.014
You should check out the original paper or

00:03:38.014 --> 00:03:41.719
other resources to decide on the parameters for creating optimizers.

00:03:41.719 --> 00:03:45.544
So, try to find in these loss functions and optimizers on your own and next,

00:03:45.544 --> 00:03:46.869
I'll show you my solution.

