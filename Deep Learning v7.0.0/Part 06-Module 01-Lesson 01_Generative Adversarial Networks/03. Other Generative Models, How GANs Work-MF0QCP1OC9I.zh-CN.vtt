WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.605
生成对抗网络是一种生成模型

00:00:04.605 --> 00:00:06.300
在该纳米学位的较早部分

00:00:06.300 --> 00:00:10.365
你已经了解到如何把循环网络作为文本的生成模型进行训练

00:00:10.365 --> 00:00:14.595
循环文本模型一次生成一个词语

00:00:14.595 --> 00:00:17.785
也可以依次产生一个词语

00:00:17.785 --> 00:00:19.554
每个图像的风格模型

00:00:19.554 --> 00:00:23.059
其中模型每次生成图像的一个像素

00:00:23.059 --> 00:00:24.929
一般说来 这种策略叫做

00:00:24.929 --> 00:00:30.254
全可见信念网络 可以追溯到 1990 年代 或是自动回归模型

00:00:30.254 --> 00:00:33.609
因为再次发现这些模型后 进行重新命名

00:00:33.609 --> 00:00:34.859
不过 如果我们想生成

00:00:34.859 --> 00:00:39.435
整个输出值 如一次生成整个图像 应该怎么办呢？

00:00:39.435 --> 00:00:44.429
生成对抗网络可以让我们一次性生成整个图像

00:00:44.429 --> 00:00:47.367
与其他几种生成模型一样

00:00:47.367 --> 00:00:49.814
生成对抗网络使用可微函数

00:00:49.814 --> 00:00:53.700
在神经网络中表现为生成器网络

00:00:53.700 --> 00:00:56.835
生成器网络利用随机噪音作为输入

00:00:56.835 --> 00:01:00.479
然后通过可微函数运行噪音

00:01:00.479 --> 00:01:04.409
然后转变噪音 重新塑造为可以识别的结构

00:01:04.409 --> 00:01:08.180
生成器网络的输出是真实图像

00:01:08.180 --> 00:01:10.079
随机选择输入噪音

00:01:10.079 --> 00:01:12.810
决定了生成器网络输出的图像类型

00:01:12.810 --> 00:01:15.030
利用许多不同的输入噪音值

00:01:15.030 --> 00:01:20.155
运行生成器网络 会生成各种不同的真实图像

00:01:20.155 --> 00:01:24.599
这些图像的目的在于成为从分布中真实数据的良好样本

00:01:24.599 --> 00:01:28.680
当然生成器网络不会立即生成真实图像

00:01:28.680 --> 00:01:30.280
需要进行训练

00:01:30.280 --> 00:01:32.879
生成模型的训练过程

00:01:32.879 --> 00:01:35.984
与监督学习模型的训练过程不同

00:01:35.984 --> 00:01:38.207
在监督学习模型中

00:01:38.207 --> 00:01:41.594
我们向模型展现交通信号灯的一个图像 我们告诉它

00:01:41.594 --> 00:01:42.840
这是交通信号灯

00:01:42.840 --> 00:01:44.623
在生成模型中

00:01:44.623 --> 00:01:47.474
没有输出和每个图像是关联的

00:01:47.474 --> 00:01:50.340
我们向模型展现许多图像

00:01:50.340 --> 00:01:53.575
让它从相同概率分布中得到更多图片

00:01:53.575 --> 00:01:56.114
但是我们怎么让模型做到这一点呢？

00:01:56.114 --> 00:01:59.969
通过调整参数 最大化概率 训练生成模型

00:01:59.969 --> 00:02:04.180
这样生成器网络会生成训练数据集

00:02:04.180 --> 00:02:07.064
不幸的是 对于许多有趣的模型

00:02:07.064 --> 00:02:10.384
它很难计算这个概率

00:02:10.384 --> 00:02:13.944
大多数生成网络采用近似法解决这个问题

00:02:13.944 --> 00:02:16.650
生成对抗网络使用近似法 其中

00:02:16.650 --> 00:02:19.530
第二个网络叫做判别器 学习指导生成器

00:02:19.530 --> 00:02:23.520
判别器是常规的神经网络分类器

00:02:23.520 --> 00:02:26.129
正如你之前几次见到的那样

00:02:26.129 --> 00:02:27.979
在训练过程中

00:02:27.979 --> 00:02:30.839
一半时间 判别器收到来自训练数据中的真实图像

00:02:30.839 --> 00:02:34.680
另一半时间收到来自生成器中的虚假图像

00:02:34.680 --> 00:02:39.685
训练判别器输出那些真实输入的概率

00:02:39.685 --> 00:02:43.080
对于真实图像 它试图对概率赋值接近 1

00:02:43.080 --> 00:02:46.254
而对于虚假图像 对概率的赋值接近 0

00:02:46.254 --> 00:02:49.580
与此同时 生成器所做的恰好相反

00:02:49.580 --> 00:02:52.425
通过训练 它输出判别器

00:02:52.425 --> 00:02:55.805
赋值概率接近 1 的图像

00:02:55.805 --> 00:02:58.460
经过一段时间后 生成器被迫产生

00:02:58.460 --> 00:03:02.104
更加真实的输出 从而欺骗判别器

00:03:02.104 --> 00:03:06.784
生成器利用随机噪音值 Z 映射它们得到值 X

00:03:06.784 --> 00:03:09.739
在生成器映射更多值 Z 的地方

00:03:09.739 --> 00:03:11.696
模型中展现出 X 的概率分布

00:03:11.696 --> 00:03:14.479
变得更加密集

00:03:14.479 --> 00:03:17.840
在真实数据的密度大于生成数据密度的地方

00:03:17.840 --> 00:03:22.099
判别器会输出较高值

00:03:22.099 --> 00:03:25.289
生成器改变了它生成的样本

00:03:25.289 --> 00:03:28.830
通过判别器的学习 沿着函数上升

00:03:28.830 --> 00:03:31.860
换句话说 生成器把样本移动到

00:03:31.860 --> 00:03:35.895
其他模型分布不够密集的区域

00:03:35.895 --> 00:03:40.514
最后生成器的分布与真实分布相匹配

00:03:40.514 --> 00:03:45.569
判别器输出各处概率的一半

00:03:45.569 --> 00:03:48.120
因为每个点可能一半是通过真实数据生成的

00:03:48.120 --> 00:03:51.324
一半是通过模型生成的

00:03:51.324 --> 00:03:53.840
两个密度是相等的

00:03:53.840 --> 00:03:56.370
我们可以认为这个过程类似于

00:03:56.370 --> 00:04:00.060
造假者和警察的竞争

00:04:00.060 --> 00:04:02.280
生成器网络像是一群

00:04:02.280 --> 00:04:06.870
造假者企图制造假币 以假乱真

00:04:06.870 --> 00:04:09.000
警察努力抓捕使用假币的造假者

00:04:09.000 --> 00:04:12.960
但还是希望其他人使用真币

00:04:12.960 --> 00:04:15.449
经过一段时间 警察越来越擅长检测假币

00:04:15.449 --> 00:04:19.329
而造假者越来越擅长造假币

00:04:19.329 --> 00:04:24.800
最后造假者被迫制造真币的完美复制版

00:04:24.800 --> 00:04:27.500
当我们在 CIFAR-10 数据集上训练简单的生成对抗网络时

00:04:27.500 --> 00:04:31.379
我们观察到它起初生成随机图像

00:04:31.379 --> 00:04:34.064
然后逐渐学会生成马

00:04:34.064 --> 00:04:37.194
飞机 卡车等图像

00:04:37.194 --> 00:04:39.375
这就是生成对抗网络的运行原理

00:04:39.375 --> 00:04:40.769
在接下来几节课中

00:04:40.769 --> 00:04:42.449
我们会介绍更多生成对抗网络的理论

00:04:42.449 --> 00:04:45.480
和更好使用生成对抗网络的技巧

