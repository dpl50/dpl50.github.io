WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.679
In the last step, we instantiated our two discriminators and our two generators,

00:00:04.679 --> 00:00:09.074
one for classifying or generating images from the X and Y domains.

00:00:09.074 --> 00:00:13.349
The next step is to define our loss functions and optimizers for training.

00:00:13.349 --> 00:00:17.850
As before, we'll want to define real and fake losses that look at the outputs of

00:00:17.850 --> 00:00:23.400
our discriminators and see how close the logits are to being real one or fake zero.

00:00:23.399 --> 00:00:27.945
We'll also need to define a new kind of loss, cycle consistency loss.

00:00:27.945 --> 00:00:31.560
This loss looks at the reconstruction error between an input,

00:00:31.559 --> 00:00:34.890
say x and a processed x, x-hat,

00:00:34.890 --> 00:00:39.164
that's gone through our two generators G_X to Y and G_Y to X,

00:00:39.164 --> 00:00:42.289
which here is referred to as F. In theory,

00:00:42.289 --> 00:00:44.869
going through these generators in a cycle will create

00:00:44.869 --> 00:00:47.809
an x-hat that's the same as the original x.

00:00:47.810 --> 00:00:52.940
Any error is measured as the absolute value difference between x-hat and x.

00:00:52.939 --> 00:00:55.750
Okay. So, this is a completely new loss type.

00:00:55.750 --> 00:00:58.965
The second new loss detail is that, in this case,

00:00:58.965 --> 00:01:01.850
we'll actually be using a least squares loss function

00:01:01.850 --> 00:01:05.195
for the discriminator as opposed to cross entropy loss.

00:01:05.194 --> 00:01:08.049
This approach is motivated by recent research.

00:01:08.049 --> 00:01:10.984
Basically, in an unsupervised approach like this,

00:01:10.984 --> 00:01:15.954
researchers observed that cross entropy loss led to a vanishing gradient problem and

00:01:15.954 --> 00:01:19.269
a least squares loss function instead was able to generate

00:01:19.269 --> 00:01:23.030
higher quality images and was a bit more stable during training.

00:01:23.030 --> 00:01:27.155
This structure is also referred to as a least squares GAN or

00:01:27.155 --> 00:01:31.540
LSGAN and you can read the original paper on this approach at this link.

00:01:31.540 --> 00:01:34.085
What this means in practice is that you'll define

00:01:34.084 --> 00:01:37.189
a real loss and fake loss function that takes in

00:01:37.189 --> 00:01:40.429
our discriminator output and computes a squared loss term

00:01:40.430 --> 00:01:43.960
between that output and the desired label one or zero.

00:01:43.959 --> 00:01:46.609
For example, for our discriminator D_X,

00:01:46.609 --> 00:01:52.099
I might pass in a real image x from our training data and I'll get some output,

00:01:52.099 --> 00:01:56.179
then I can essentially calculate a real error as a mean square loss

00:01:56.180 --> 00:02:00.720
by squaring the difference between that output and a real label one.

00:02:00.719 --> 00:02:04.480
In Python code, these two asterisks mean raised to a power of two.

00:02:04.480 --> 00:02:07.390
So, I'm taking the squared difference of the output and

00:02:07.390 --> 00:02:11.180
the label one and then I'm taking the mean of all of these values.

00:02:11.180 --> 00:02:15.939
So, this is a mean squared loss and I can do something really similar for a fake image,

00:02:15.939 --> 00:02:18.969
only instead of comparing the output to the value one,

00:02:18.969 --> 00:02:23.509
I'm going to compare it to the value zero and just end up squaring the output term.

00:02:23.509 --> 00:02:24.944
Okay. So, in this cell,

00:02:24.944 --> 00:02:28.289
I want you to try to fine in these three loss functions.

00:02:28.289 --> 00:02:31.179
The first two taking the outputs from our discriminator.

00:02:31.180 --> 00:02:34.210
The real loss function should compute a mean squared error between

00:02:34.210 --> 00:02:38.110
this output and real labels and the fake function should do the same thing,

00:02:38.110 --> 00:02:39.575
but with fake labels.

00:02:39.574 --> 00:02:43.209
Lastly, I have a weight function that will take in a real image,

00:02:43.210 --> 00:02:45.985
its reconstruction and a Lambda weight.

00:02:45.985 --> 00:02:50.410
This is our cycle consistency loss function and it should do two things.

00:02:50.409 --> 00:02:52.879
First, it will calculate the reconstruction loss.

00:02:52.879 --> 00:02:56.569
So, the absolute value difference between these two inputs,

00:02:56.569 --> 00:02:58.715
the real image and its reconstruction.

00:02:58.715 --> 00:03:01.280
These are going to be pixel-wise differences and so you can

00:03:01.280 --> 00:03:03.985
take the mean of the absolute value difference here.

00:03:03.985 --> 00:03:07.920
Then, it should multiply that loss term by the past and weight value here.

00:03:07.919 --> 00:03:10.109
If you recall from Juneon's videos,

00:03:10.110 --> 00:03:12.710
the Lambda weight basically tells us how weighty or

00:03:12.710 --> 00:03:15.760
how important the cycle consistency loss term is.

00:03:15.759 --> 00:03:18.500
Okay. Then there's one more thing we have to do to complete

00:03:18.500 --> 00:03:21.155
our optimization strategy and that's defined

00:03:21.155 --> 00:03:24.469
atom optimizers for our discriminator and generators.

00:03:24.469 --> 00:03:27.800
In this case, I want you to create three different optimizers,

00:03:27.800 --> 00:03:31.010
one for each of our discriminators X and Y and

00:03:31.009 --> 00:03:34.474
a third attached to the parameters from both of our generators.

00:03:34.474 --> 00:03:37.984
I'm getting those parameters by adding them up as lists in this line.

00:03:37.985 --> 00:03:39.365
There are other ways to do this,

00:03:39.365 --> 00:03:41.379
but I think this leads to a nice solution.

00:03:41.379 --> 00:03:44.419
So, your job will be to define the hyperparameters here by

00:03:44.419 --> 00:03:47.839
looking at existing papers or other resources that you find.

00:03:47.840 --> 00:03:51.860
Try completing the loss functions above and filling in these hyperparameters.

00:03:51.860 --> 00:03:54.130
Next, I'll show you one solution.

