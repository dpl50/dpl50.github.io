WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:04.320
So after we have our content and style features and gram matrices,

00:00:04.320 --> 00:00:07.669
next we need to define style and content losses.

00:00:07.669 --> 00:00:10.620
Alongside these, we need to define loss weights.

00:00:10.619 --> 00:00:13.739
This way, we can iteratively update our target image.

00:00:13.740 --> 00:00:18.254
First up, we're defining our style weights for each of our individual style layers.

00:00:18.254 --> 00:00:20.969
Notice that conv4_2 is excluded here.

00:00:20.969 --> 00:00:23.399
Now, these are just weights that are going to give one set of

00:00:23.399 --> 00:00:25.939
style features more importance than another's.

00:00:25.940 --> 00:00:29.640
For example, I prefer to weigh earlier layers a little bit more.

00:00:29.640 --> 00:00:34.064
These features are often larger due to the spatial size of these feature maps.

00:00:34.064 --> 00:00:38.129
Whereas weighting later layers might emphasize more fine-grain features.

00:00:38.130 --> 00:00:41.645
But again, this is really a preference and up to you to customize.

00:00:41.645 --> 00:00:45.100
I'd recommend keeping the values within the zero to one range.

00:00:45.100 --> 00:00:46.704
Then we have are alpha and beta,

00:00:46.704 --> 00:00:50.659
which I'm going to descriptively name our content weight and our style weight.

00:00:50.659 --> 00:00:54.289
Earlier, we discussed this as a ratio that makes sure that style and

00:00:54.289 --> 00:00:58.214
content are equally important in the target image creation process.

00:00:58.215 --> 00:01:00.505
Because of how style loss is calculated,

00:01:00.505 --> 00:01:04.840
we basically want to give our style loss a much larger weight than the content loss.

00:01:04.840 --> 00:01:08.840
Here, it's 1 times 10 to the 6th and content loss is just one.

00:01:08.840 --> 00:01:10.439
Now, if beta is too large,

00:01:10.439 --> 00:01:12.780
you may see too much of a stylized effect,

00:01:12.780 --> 00:01:15.060
but these values are good starting points.

00:01:15.060 --> 00:01:17.519
Next, we enter the iteration loop,

00:01:17.519 --> 00:01:20.584
and here's where you're actually going to be changing your target image.

00:01:20.584 --> 00:01:22.709
Now, this is not a training process,

00:01:22.709 --> 00:01:26.239
so it's arbitrary where you stop updating the target image.

00:01:26.239 --> 00:01:28.474
I'd recommend at least 2,000 iterations,

00:01:28.474 --> 00:01:30.799
but you may want to do more or less depending on

00:01:30.799 --> 00:01:33.619
your computing resources and desired effect.

00:01:33.620 --> 00:01:35.365
So, in this iteration loop,

00:01:35.364 --> 00:01:38.405
I'm going to ask you to calculate the content loss first.

00:01:38.405 --> 00:01:40.849
This will just be the mean square difference between

00:01:40.849 --> 00:01:44.059
the target and content representations.

00:01:44.060 --> 00:01:46.545
I've given you some example code up here.

00:01:46.545 --> 00:01:50.299
We can get those representations by getting the features from our target image,

00:01:50.299 --> 00:01:53.325
and then comparing those features at a particular layer,

00:01:53.325 --> 00:01:55.159
in this case conv4_2,

00:01:55.159 --> 00:01:58.229
to the features at that layer for our content image.

00:01:58.230 --> 00:02:00.650
We're going to subtract these two representations and

00:02:00.650 --> 00:02:03.180
then square that difference and calculate the mean.

00:02:03.180 --> 00:02:05.285
This will give us our content loss.

00:02:05.284 --> 00:02:09.125
Next in this loop, you're going to do something similar for the style loss.

00:02:09.125 --> 00:02:10.879
Only this time, you have to go through

00:02:10.879 --> 00:02:14.000
multiple layers for our multiple representations for style.

00:02:14.000 --> 00:02:18.205
Recall that each of our relevant layers was listed in our style_weights dictionary above.

00:02:18.205 --> 00:02:20.930
Here, I'm assuming you've calculated our target features so

00:02:20.930 --> 00:02:23.795
you can access a single target feature by layer.

00:02:23.794 --> 00:02:25.639
You'll get some style features from

00:02:25.639 --> 00:02:28.944
the target image and calculate the gram matrix for that layer.

00:02:28.944 --> 00:02:32.509
Then you have to compare with this style_gram for the style image at

00:02:32.509 --> 00:02:36.409
that layer weighting it with our specified style weight for this layer.

00:02:36.409 --> 00:02:38.090
Here, these are going to be added up and

00:02:38.090 --> 00:02:40.400
normalized by the number of values in that layer.

00:02:40.400 --> 00:02:44.640
Finally, you should be able to add up everything and calculate a total loss.

00:02:44.639 --> 00:02:49.704
This is what will be used to update the target image using typical back propagation.

00:02:49.705 --> 00:02:52.835
So, try out completing this loss code on your own.

00:02:52.835 --> 00:02:56.670
This is the last piece of code you'll need to implement style transfer.

00:02:56.669 --> 00:03:01.329
Then, you'll be able to test this method on target images of your own design.

